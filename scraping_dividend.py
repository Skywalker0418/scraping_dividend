# -*- coding: utf-8 -*-
"""scraping dividend.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16gTej05IzmFP5Xe0dp_GWaYVOAoW_qq9

# Analysis of saudi market dividend
"""

import os
import re
import csv
import requests
import json
import numpy as np
import pandas as pd
from bs4 import BeautifulSoup

# import warnings
# warnings.filterwarnings('ignore')

url = 'https://cdn.saudiexchange.sa/wps/portal/saudiexchange/ourmarkets/main-market-watch/!ut/p/z1/04_Sj9CPykssy0xPLMnMz0vMAfIjo8ziTR3NDIw8LAz8LVxcnA0C3bwtPLwM_I0MzMz1w1EVGAQHmAIVBPga-xgEGbgbmOlHEaPfAAdwNCCsPwpNia-7mUGgn2Ogv5G5qYFBsBG6AixOBCvA44bg1Dz9gtzQCIPMgHQAsqCDtA!!/p0/IZ7_IPG41I82KGASC06S67RB9A0080=CZ6_5A602H80O8DDC0QFK8HJ0O2067=NJgetMainNomucMarketDetails=/?sectorParameter=&tableViewParameter=1&iswatchListSelected=NO&requestLocale=en&_=1691337352599'
response = requests.get(url)
json_data = json.loads(response.text)
companyList = json_data['data']

fields = ['sectorName', 'companySymbol', 'acrynomName', 'companyUrl']
csv_file = open('company_data.csv', 'w', newline='', encoding='utf-8')
csv_writer = csv.DictWriter(csv_file, fields)
csv_writer.writeheader()
csv_file.close()

with open('company_data.csv', "a", newline='', encoding="utf-8") as fp:
  for companyData in companyList:
    # print(companyData['sectorName'], companyData['companySymbol'], companyData['acrynomName'], companyData['companyUrl'])
    wr = csv.writer(fp, dialect='excel')
    wr.writerow([companyData['sectorName'], companyData['companySymbol'], companyData['acrynomName'], companyData['companyUrl']])

df_company = pd.read_csv('company_data.csv')
df_company

fields = ['sectorName', 'symbol', 'name', 'announced', 'eligibility_date', 'distribution_date', 'distribution_way', 'dividend_per_share', 'company_url']
csv_file = open('data.csv', 'w', newline='', encoding='utf-8')
csv_writer = csv.DictWriter(csv_file, fields)
csv_writer.writeheader()
csv_file.close()

df_company = df_company.reset_index()

"""# Web data extraction"""

base_url = 'https://cdn.saudiexchange.sa'
for index, row in df_company.iterrows():

  url = base_url + row['companyUrl']
  response = requests.get(url)
  soup = BeautifulSoup(response.text, 'html.parser')
  dividend_div = soup.find('div', class_='announcement_corporate dividends')
  nextSibling = dividend_div.find_next_sibling("div")
  with open('data.csv', "a", newline='', encoding="utf-8-sig") as fp:
    if not nextSibling == None:
      trList = nextSibling.find('tbody').find_all('tr')
      for tr in trList:
        tdList = tr.find_all('td')
        announced = tdList[0].text
        eligibility_date = tdList[1].text
        distribution_date = tdList[2].text
        distribution_way = tdList[3].text
        dividend_per_share = tdList[4].text
        wr = csv.writer(fp, dialect='excel')
        wr.writerow([row['sectorName'], row['companySymbol'], row['acrynomName'], announced, eligibility_date, distribution_date, distribution_way, dividend_per_share, row['companyUrl']])

df = pd.read_csv('data.csv')
df

"""# Download"""

from google.colab import files
files.download('data.csv')